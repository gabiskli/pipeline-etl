# Pipeline de ETL com Python
üß∂ Construindo um banco de dados com informa√ß√µes sobre linhas de croch√™ / tric√¥üß∂

‚úÖ Status: Conclu√≠do ‚úÖ


## Tabela de conte√∫dos
* [Sobre o Projeto](#-sobre-o-projeto)
* [Tabela de Conte√∫dos](#tabela-de-conte√∫dos)
* [Como utilizar o Projeto](#-como-utilizar-o-projeto)
	* [Etapas do Processo ETL](#etapas-do-processo)
	* [Arquivos](#arquivos-do-projeto)
	* [Instru√ß√µes de Uso](#instru√ß√µes-de-uso)
* [Tecnologias](#%EF%B8%8F-tecnologias-utilizadas)
* [Pr√≥ximos Passos](#-pr√≥ximos-passos-)
* [Licen√ßa](#-licen√ßa)

## üíª Sobre o Projeto

O projeto consiste em uma Pipeline ETL (Extra√ß√£o, Transforma√ß√£o e Carregamento) com o objetivo de obter um banco de dados de linhas de croch√™ e tric√¥ presentes no mercado internacional.

Projeto desenvolvido durante o Bootcamp Santander 2023 - Ci√™ncia de Dados com Python.

## üîç Como utilizar o projeto


### Etapas do Processo

#### 1.  Extra√ß√£o:
Ser√° feita usando web scraping com python retirando dados do site [YarnSubs](https://.yarnsub.com/).

A extra√ß√£o foi dividida em duas etapas por causa da configura√ß√£o do site. A primeira parte envolve a extra√ß√£o dos links de cada linha. E a segunda parte utilizar√° esse arquivo para extrair as informa√ß√µes de cada linha, que montar√° o banco de dados.
#### 2.  Transforma√ß√£o: 
Ser√£o criadas novas colunas, assim como reclassifica√ß√£o e normaliza√ß√£o dos dados.
#### 3.  Carregamento:
A sa√≠da do pipeline ser√° dada por um arquivo csv final, com as informa√ß√µes limpas.

### Arquivos do Projeto

- ``extracao-1.py``: Cont√©m o c√≥digo em Python da primeira parte da extra√ß√£o dos dados.
- ``extracao-2.py``: Cont√©m o c√≥digo da segunda parte da extra√ß√£o dos dados.
- ``tranformacao-carregamento.py``: Cont√©m o c√≥digo da parte final do processo de ETL.
- ``Yarn_Links.csv``: Arquivo de sa√≠da da primeira parte da extra√ß√£o que ser√° usada como input para a segunda parte.
- ``Yarn_Information.csv``: Arquivo de sa√≠da final da extra√ß√£o que ser√° usado como input na fase de transforma√ß√£o dos dados.
- ``Yarn_Info_Clean.csv``: Arquivo final do programa que cont√©m o banco de dados limpo.

### Instru√ß√µes de Uso
- Certifique-se de ter Pyhton 3.x instalado.
- Instale as seguintes bibliotecas
(c√≥digo)
- Execute o arquivo ``extracao-parte-1.py``
- Com o arquivo final de links (``Yarn_Links.csv``) , execute o arquivo ``extra√ß√£o-parte-2.py`` 
- Por fim, utilizando o arquivo csv com as informa√ß√µes brutas (``Yarn_Information.csv``), execute o arquivo ``tranformacao-carregamento.py`` para obter o arquivo csv final.

##  üõ†Ô∏è Tecnologias Utilizadas

Nesse projeto foram utilizadas as seguintes tecnologias:

* [Python 3.x](https://docs.python.org/3/)

* [Pandas](https://pandas.pydata.org/docs/)

* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

* [Regex](https://docs.python.org/3/library/re.html)

## üöß Pr√≥ximos Passos üöß

A ideia de criar essa pipeline ETL faz parte de um projeto pessoal maior onde os dados extra√≠do aqui ser√£o utilizados para criar um programa em Python para compara√ß√£o de fios. O programa ser√° baseado no pr√≥prio site [YarnSubs](https://yarnsub.com/), onde a etapa de web scraping foi realizada.

## üìã Licen√ßa
Este projeto est√° sob a licen√ßa [MIT License](/LICENSE)

üíúFeito por Gabriela Klitzke. 
[Entre em contato!](https://www.linkedin.com/in/gabrielaklitzke/)
