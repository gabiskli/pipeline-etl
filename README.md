# Pipeline de ETL com Python
ğŸ§¶ Construindo um banco de dados com informaÃ§Ãµes sobre linhas de crochÃª / tricÃ´ğŸ§¶

<center>âœ… Status: ConcluÃ­do âœ…</center>


## Tabela de conteÃºdos
* [Sobre o Projeto](#sobre-o-projeto)
* [Tabela de ConteÃºdos](#tabela-de-conteudos)
* [Como utilizar o Projeto](#como-utilizar-o-projeto)
	* [Etapas do Processo ETL](#etapas-do-processo)
	* [Arquivos](#arquivos-do-projeto)
	* [InstruÃ§Ãµes de Uso](#instruÃ§Ãµes-de-uso)
* [Tecnologias](#tecnologias-utilizadas)
* [PrÃ³ximos Passos](#ğŸš§-prÃ³ximos-passos-ğŸš§)
* [LicenÃ§a](#ğŸ”—-licenÃ§a)

## ğŸ’» Sobre o Projeto

O projeto consiste em uma Pipeline ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carregamento) com o objetivo de obter um banco de dados de linhas de crochÃª e tricÃ´ presentes no mercado internacional.

Projeto desenvolvido durante o Bootcamp Santander 2023 - CiÃªncia de Dados com Python.

## ğŸ” Como utilizar o projeto


### Etapas do Processo

#### 1.  ExtraÃ§Ã£o:
SerÃ¡ feita usando web scraping com python retirando dados do site [YarnSubs](https://.yarnsub.com/).

A extraÃ§Ã£o foi dividida em duas etapas por causa da configuraÃ§Ã£o do site. A primeira parte envolve a extraÃ§Ã£o dos links de cada linha. E a segunda parte utilizarÃ¡ esse arquivo para extrair as informaÃ§Ãµes de cada linha, que montarÃ¡ o banco de dados.
#### 2.  TransformaÃ§Ã£o: 
SerÃ£o criadas novas colunas, assim como reclassificaÃ§Ã£o e normalizaÃ§Ã£o dos dados.
#### 3.  Carregamento:
A saÃ­da do pipeline serÃ¡ dada por um arquivo csv final, com as informaÃ§Ãµes limpas.

### Arquivos do Projeto

- ``extracao-1.py``: ContÃ©m o cÃ³digo em Python da primeira parte da extraÃ§Ã£o dos dados.
- ``extracao-2.py``: ContÃ©m o cÃ³digo da segunda parte da extraÃ§Ã£o dos dados.
- ``tranformacao-carregamento.py``: ContÃ©m o cÃ³digo da parte final do processo de ETL.
- ``Yarn_Links.csv``: Arquivo de saÃ­da da primeira parte da extraÃ§Ã£o que serÃ¡ usada como input para a segunda parte.
- ``Yarn_Information.csv``: Arquivo de saÃ­da final da extraÃ§Ã£o que serÃ¡ usado como input na fase de transformaÃ§Ã£o dos dados.
- ``Yarn_Info_Clean.csv``: Arquivo final do programa que contÃ©m o banco de dados limpo.

### InstruÃ§Ãµes de Uso
- Certifique-se de ter Pyhton 3.x instalado.
- Instale as seguintes bibliotecas
(cÃ³digo)
- Execute o arquivo ``extracao-parte-1.py``
- Com o arquivo final de links (``Yarn_Links.csv``) , execute o arquivo ``extraÃ§Ã£o-parte-2.py`` 
- Por fim, utilizando o arquivo csv com as informaÃ§Ãµes brutas (``Yarn_Information.csv``), execute o arquivo ``tranformacao-carregamento.py`` para obter o arquivo csv final.

##  ğŸ› ï¸ Tecnologias Utilizadas

Nesse projeto foram utilizadas as seguintes tecnologias:

* [Python 3.x](https://docs.python.org/3/)

* [Pandas](https://pandas.pydata.org/docs/)

* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

* [Regex](https://docs.python.org/3/library/re.html)

## ğŸš§ PrÃ³ximos Passos ğŸš§

A ideia de criar essa pipeline ETL faz parte de um projeto pessoal maior onde os dados extraÃ­do aqui serÃ£o utilizados para criar um programa em Python para comparaÃ§Ã£o de fios. O programa serÃ¡ baseado no prÃ³prio site [YarnSubs](https://yarnsub.com/), onde a etapa de web scraping foi realizada.

## ğŸ“‹ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a [MIT License](/LICENSE)

ğŸ’œFeito por Gabriela Klitzke. 
[Entre em contato!](https://www.linkedin.com/in/gabrielaklitzke/)
